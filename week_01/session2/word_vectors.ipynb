{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, sys\n",
    "import numpy as np\n",
    "from heapq import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(filename):\n",
    "    fin = io.open(filename, 'r', encoding='utf-8', newline='\\n')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.asarray(list(map(float, tokens[1:])))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ** Word vectors ** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading word vectors\n",
    "\n",
    "print('')\n",
    "print(' ** Word vectors ** ')\n",
    "print('')\n",
    "\n",
    "word_vectors = load_vectors('wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function computes the cosine similarity between vectors u and v\n",
    "\n",
    "def cosine(u, v):\n",
    "    ## FILL CODE\n",
    "    \n",
    "    return u @ v/ (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "## This function returns the word corresponding to \n",
    "## nearest neighbor vector of x\n",
    "## The list exclude_words can be used to exclude some\n",
    "## words from the nearest neighbors search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity(queen, woman) = 0.361\n",
      "similarity(apple, banana) = 0.431\n",
      "similarity(apple, tiger) = 0.212\n"
     ]
    }
   ],
   "source": [
    "# compute similarity between words\n",
    "\n",
    "print('similarity(queen, woman) = %.3f' %\n",
    "      cosine(word_vectors['queen'], word_vectors['woman']))\n",
    "print('similarity(apple, banana) = %.3f' %\n",
    "      cosine(word_vectors['apple'], word_vectors['banana']))\n",
    "print('similarity(apple, tiger) = %.3f' %\n",
    "      cosine(word_vectors['apple'], word_vectors['tiger']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for nearest neighbors\n",
    "\n",
    "def nearest_neighbor(x, word_vectors, exclude_words=[]):\n",
    "    best_score = -1.0\n",
    "    best_word = ''\n",
    "\n",
    "    ## FILL CODE'\n",
    "    #exclude_words.append(x)\n",
    "    for i in word_vectors:\n",
    "        sim = cosine(x, word_vectors[i])\n",
    "        if sim > best_score:\n",
    "            best_score = sim\n",
    "            best_word = i      \n",
    "\n",
    "\n",
    "    return best_word\n",
    "\n",
    "## This function return the words corresponding to the\n",
    "## K nearest neighbors of vector x.\n",
    "## You can use the functions heappush and heappop.\n",
    "\n",
    "def knn(x, vectors, k):\n",
    "    heap = []\n",
    "\n",
    "    ## FILL CODE\n",
    "    for i in vectors:\n",
    "        dist = cosine(x, vectors[i])\n",
    "        if len(heap) < k:\n",
    "            heap.append((dist, i))\n",
    "            \n",
    "        else:\n",
    "            m = min(heap, key= lambda x:x[0])\n",
    "            idx_min = heap.index(m)\n",
    "            if dist > m[0]:\n",
    "                heap[idx_min] = dist, i      \n",
    "    \n",
    "\n",
    "    return sorted(heap, key= lambda x:x[0],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nearest neighbor of cat is: cat\n"
     ]
    }
   ],
   "source": [
    "print('The nearest neighbor of cat is: ' +\n",
    "      nearest_neighbor(word_vectors['cat'], word_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nearest neighbor of cat is: cat\n",
      "\n",
      "cat\n",
      "--------------\n",
      "cat\t1.000\n",
      "cats\t0.732\n",
      "dog\t0.638\n",
      "pet\t0.573\n",
      "rabbit\t0.549\n"
     ]
    }
   ],
   "source": [
    "# looking at nearest neighbors of a word\n",
    "\n",
    "print('The nearest neighbor of cat is: ' +\n",
    "      nearest_neighbor(word_vectors['cat'], word_vectors))\n",
    "\n",
    "knn_cat = knn(word_vectors['cat'], word_vectors, 5)\n",
    "print('')\n",
    "print('cat')\n",
    "print('--------------')\n",
    "for score, word in knn(word_vectors['cat'], word_vectors, 5):\n",
    "    print(word + '\\t%.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function return the word d, such that a:b and c:d\n",
    "## verifies the same relation\n",
    "\n",
    "def analogy(a, b, c, word_vectors):\n",
    "    ## FILL CODE\n",
    "    a = a.lower()\n",
    "    b = b.lower()\n",
    "    c = c.lower()  \n",
    "    \n",
    "    return nearest_neighbor((word_vectors[b] -word_vectors[a]  + word_vectors[c]), word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "king - man + woman = woman\n"
     ]
    }
   ],
   "source": [
    "# Word analogies\n",
    "\n",
    "print('')\n",
    "print('king - man + woman = ' + analogy('king', 'man', 'woman', word_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "similarity(genius, man) = 0.445\n",
      "similarity(genius, woman) = 0.325\n"
     ]
    }
   ],
   "source": [
    "## A word about biases in word vectors:\n",
    "\n",
    "print('')\n",
    "print('similarity(genius, man) = %.3f' %\n",
    "      cosine(word_vectors['man'], word_vectors['genius']))\n",
    "print('similarity(genius, woman) = %.3f' %\n",
    "      cosine(word_vectors['woman'], word_vectors['genius']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the association strength between:\n",
    "##   - a word w\n",
    "##   - two sets of attributes A and B\n",
    "\n",
    "def association_strength(w, A, B, vectors):\n",
    "    strength = 0.0\n",
    "    ## FILL CODE\n",
    "    card_A = 1/len(A)\n",
    "    card_B = 1/len(B)\n",
    "    \n",
    "    ass_A = card_A * np.sum([cosine(vectors[w], vectors[a]) for a in A])\n",
    "    ass_B = card_B * np.sum([cosine(vectors[w], vectors[b]) for b in B])\n",
    "    \n",
    "    return ass_A - ass_B\n",
    "\n",
    "## Perform the word embedding association test between:\n",
    "##   - two sets of words X and Y\n",
    "##   - two sets of attributes A and B\n",
    "\n",
    "def weat(X, Y, A, B, vectors):\n",
    "    score = 0.0\n",
    "    ## FILL CODE\n",
    "    ass_x = np.sum([association_strength(x, A, B, vectors) for x in X])\n",
    "    ass_y = np.sum([association_strength(y, A, B, vectors) for y in Y])\n",
    "    return ass_x - ass_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word embedding association test: 0.847\n"
     ]
    }
   ],
   "source": [
    "## Replicate one of the experiments from:\n",
    "##\n",
    "## Semantics derived automatically from language corpora contain human-like biases\n",
    "## Caliskan, Bryson, Narayanan (2017)\n",
    "\n",
    "career = ['executive', 'management', 'professional', 'corporation', \n",
    "          'salary', 'office', 'business', 'career']\n",
    "family = ['home', 'parents', 'children', 'family',\n",
    "          'cousins', 'marriage', 'wedding', 'relatives']\n",
    "male = ['john', 'paul', 'mike', 'kevin', 'steve', 'greg', 'jeff', 'bill']\n",
    "female = ['amy', 'joan', 'lisa', 'sarah', 'diana', 'kate', 'ann', 'donna']\n",
    "\n",
    "print('')\n",
    "print('Word embedding association test: %.3f' %\n",
    "      weat(career, family, male, female, word_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
