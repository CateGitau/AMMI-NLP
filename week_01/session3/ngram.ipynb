{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, sys, math, re\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "\n",
    "def load_data(filename):\n",
    "    fin = io.open(filename, 'r', encoding='utf-8')\n",
    "    data = []\n",
    "    vocab = defaultdict(lambda:0)\n",
    "    for line in fin:\n",
    "        sentence = line.split()\n",
    "        data.append(sentence)\n",
    "        for word in sentence:\n",
    "            vocab[word] += 1\n",
    "    return data, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_words(data, vocab, mincount = 10):\n",
    "    ## FILL CODE\n",
    "    # replace words in data that are not in the vocab \n",
    "    # or have a count that is below mincount\n",
    "    data_with_unk = data[:]\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        for word in range(len(data[i])):\n",
    "            if vocab[data[i][word]] < mincount:\n",
    "                data_with_unk[i][word] = \"unk\"\n",
    "                \n",
    "    return data_with_unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load training set\n",
      "load validation set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['<s>', 'we', 'unk', 'over', 'the', 'unk', 'to', 'do', 'that.', '</s>'],\n",
       " ['<s>', 'sami', 'should', 'be', 'unk', 'of', 'the', 'unk', '</s>'],\n",
       " ['<s>', 'my', 'father', \"won't\", 'unk', 'that.', '</s>'],\n",
       " ['<s>',\n",
       "  'tom',\n",
       "  'unk',\n",
       "  'to',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'three',\n",
       "  'times',\n",
       "  'a',\n",
       "  'week.',\n",
       "  '</s>'],\n",
       " ['<s>', 'unk', 'unk', 'unk', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'his',\n",
       "  'unk',\n",
       "  'was',\n",
       "  'an',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'for',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  \"weren't\",\n",
       "  'you',\n",
       "  'the',\n",
       "  'one',\n",
       "  'who',\n",
       "  'was',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'tom',\n",
       "  'and',\n",
       "  'mary',\n",
       "  'they',\n",
       "  \"wouldn't\",\n",
       "  'be',\n",
       "  'unk',\n",
       "  'to',\n",
       "  'do',\n",
       "  'that?',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'unk',\n",
       "  'do',\n",
       "  'you',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'where',\n",
       "  'the',\n",
       "  'money',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>', 'are', 'these', 'children', 'unk', '</s>'],\n",
       " ['<s>', 'this', 'park', \"isn't\", 'open', 'to', 'the', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'sami',\n",
       "  'unk',\n",
       "  'so',\n",
       "  'much',\n",
       "  'unk',\n",
       "  'to',\n",
       "  'the',\n",
       "  'work',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>', 'i', 'need', 'you', 'to', 'unk', 'these', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'his',\n",
       "  'unk',\n",
       "  'she',\n",
       "  'unk',\n",
       "  'would',\n",
       "  'be',\n",
       "  'rather',\n",
       "  'over',\n",
       "  'unk',\n",
       "  'than',\n",
       "  'under',\n",
       "  'it.',\n",
       "  '</s>'],\n",
       " ['<s>', 'tom', 'and', 'mary', 'are', 'unk', \"aren't\", 'they?', '</s>'],\n",
       " ['<s>', 'tom', 'took', 'the', 'unk', 'away', 'from', 'mary.', '</s>'],\n",
       " ['<s>',\n",
       "  'you',\n",
       "  'unk',\n",
       "  'the',\n",
       "  'world',\n",
       "  'to',\n",
       "  'unk',\n",
       "  'you',\n",
       "  'really',\n",
       "  'do.',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'everyone',\n",
       "  'in',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'has',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'and',\n",
       "  'unk',\n",
       "  'now',\n",
       "  'all',\n",
       "  'our',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'have',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'tom',\n",
       "  'is',\n",
       "  'the',\n",
       "  'one',\n",
       "  \"that's\",\n",
       "  'been',\n",
       "  'unk',\n",
       "  'our',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  \"i'm\",\n",
       "  'the',\n",
       "  'only',\n",
       "  'one',\n",
       "  'here',\n",
       "  'who',\n",
       "  \"doesn't\",\n",
       "  'speak',\n",
       "  'french.',\n",
       "  '</s>'],\n",
       " ['<s>', 'i', 'love', 'unk', 'on', 'unk', 'or', 'other', 'unk', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'tom',\n",
       "  'and',\n",
       "  'mary',\n",
       "  'said',\n",
       "  'that',\n",
       "  'they',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'meet',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>', 'some', 'people', 'call', 'unk', 'an', 'unk', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'no',\n",
       "  'one',\n",
       "  'has',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'me',\n",
       "  'what',\n",
       "  'i',\n",
       "  'can',\n",
       "  'and',\n",
       "  \"can't\",\n",
       "  'do',\n",
       "  'with',\n",
       "  'my',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>', 'i', 'had', 'the', 'unk', '</s>'],\n",
       " ['<s>', 'the', 'girl', 'who', 'unk', 'at', 'the', 'unk', 'is', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'why',\n",
       "  'is',\n",
       "  'mary',\n",
       "  'going',\n",
       "  'with',\n",
       "  'him',\n",
       "  'to',\n",
       "  'the',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'he',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'for',\n",
       "  'a',\n",
       "  'long',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'to',\n",
       "  'find',\n",
       "  'a',\n",
       "  'unk',\n",
       "  'to',\n",
       "  'the',\n",
       "  'problem.',\n",
       "  '</s>'],\n",
       " ['<s>', 'sami', 'unk', 'the', 'bus', 'all', 'the', 'time.', '</s>'],\n",
       " ['<s>',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'of',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'and',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'may',\n",
       "  'unk',\n",
       "  'the',\n",
       "  'key',\n",
       "  'to',\n",
       "  'unk',\n",
       "  'this',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  \"i'll\",\n",
       "  'tell',\n",
       "  'tom',\n",
       "  'and',\n",
       "  'mary',\n",
       "  \"we're\",\n",
       "  'going',\n",
       "  'with',\n",
       "  'them.',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'and',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'of',\n",
       "  'unk',\n",
       "  'now',\n",
       "  'went',\n",
       "  'unk',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'no',\n",
       "  'unk',\n",
       "  'but',\n",
       "  'being',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'in',\n",
       "  'everything',\n",
       "  'her',\n",
       "  'mother',\n",
       "  'unk',\n",
       "  'or',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'not',\n",
       "  'only',\n",
       "  'has',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'only',\n",
       "  'been',\n",
       "  'unk',\n",
       "  'once',\n",
       "  'since',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'but',\n",
       "  'he',\n",
       "  'has',\n",
       "  'never',\n",
       "  'been',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'for',\n",
       "  'unk',\n",
       "  'with',\n",
       "  'over',\n",
       "  'a',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  \"that's\",\n",
       "  'unk',\n",
       "  'a',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>', 'layla', 'was', 'unk', 'for', 'the', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'mary',\n",
       "  'said',\n",
       "  'that',\n",
       "  \"wasn't\",\n",
       "  'the',\n",
       "  'real',\n",
       "  'reason',\n",
       "  'she',\n",
       "  'did',\n",
       "  'that.',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'said',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'would',\n",
       "  'not',\n",
       "  'take',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>', 'they', 'unk', 'their', 'unk', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'tom',\n",
       "  'and',\n",
       "  'mary',\n",
       "  'told',\n",
       "  'me',\n",
       "  'they',\n",
       "  \"couldn't\",\n",
       "  'do',\n",
       "  'that.',\n",
       "  '</s>'],\n",
       " ['<s>', 'he', 'went', 'to', 'the', 'unk', 'of', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'he',\n",
       "  \"can't\",\n",
       "  'tell',\n",
       "  'a',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'from',\n",
       "  'a',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'but',\n",
       "  'he',\n",
       "  'can',\n",
       "  'name',\n",
       "  'them',\n",
       "  'in',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>', 'you', \"couldn't\", 'unk', 'the', 'unk', 'could', 'you?', '</s>'],\n",
       " ['<s>', 'unk', 'is', 'the', 'language', 'of', 'the', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'tom',\n",
       "  'knew',\n",
       "  'that',\n",
       "  'mary',\n",
       "  'wanted',\n",
       "  'him',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'her',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'with',\n",
       "  'him.',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'tom',\n",
       "  'has',\n",
       "  'been',\n",
       "  'unk',\n",
       "  'in',\n",
       "  'boston',\n",
       "  'with',\n",
       "  'his',\n",
       "  'father.',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'tom',\n",
       "  'and',\n",
       "  'mary',\n",
       "  'have',\n",
       "  'lost',\n",
       "  'unk',\n",
       "  'of',\n",
       "  'the',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'best',\n",
       "  'unk',\n",
       "  'i',\n",
       "  'can',\n",
       "  'be.',\n",
       "  '</s>'],\n",
       " ['<s>', 'i', 'have', 'unk', 'the', 'unk', '</s>'],\n",
       " ['<s>', 'i', 'like', 'the', 'way', 'she', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'they',\n",
       "  'said',\n",
       "  'that',\n",
       "  \"they'd\",\n",
       "  'help',\n",
       "  'us',\n",
       "  'do',\n",
       "  'that.',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'those',\n",
       "  'who',\n",
       "  'have',\n",
       "  'never',\n",
       "  'thought',\n",
       "  'about',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'of',\n",
       "  'life',\n",
       "  'should',\n",
       "  'not',\n",
       "  'study',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'we',\n",
       "  'were',\n",
       "  'able',\n",
       "  'to',\n",
       "  'make',\n",
       "  'a',\n",
       "  'unk',\n",
       "  'with',\n",
       "  'them.',\n",
       "  '</s>'],\n",
       " ['<s>', 'will', 'you', 'please', 'pass', 'the', 'unk', '</s>'],\n",
       " ['<s>', 'i', 'unk', 'on', 'the', 'unk', '</s>'],\n",
       " ['<s>', 'they', 'probably', 'did', 'that', 'by', 'themselves.', '</s>'],\n",
       " ['<s>',\n",
       "  'tom',\n",
       "  'was',\n",
       "  'in',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'for',\n",
       "  'three',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'this',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'while',\n",
       "  'i',\n",
       "  'was',\n",
       "  'unk',\n",
       "  'over',\n",
       "  'whether',\n",
       "  'i',\n",
       "  'should',\n",
       "  'unk',\n",
       "  'such',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'through',\n",
       "  'the',\n",
       "  'book',\n",
       "  'and',\n",
       "  'read',\n",
       "  'unk',\n",
       "  'and',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'i',\n",
       "  'was',\n",
       "  'unk',\n",
       "  'over',\n",
       "  'whether',\n",
       "  'i',\n",
       "  'should',\n",
       "  'unk',\n",
       "  'such',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'through',\n",
       "  'the',\n",
       "  'book',\n",
       "  'and',\n",
       "  'read',\n",
       "  'unk',\n",
       "  'and',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'i',\n",
       "  'was',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'the',\n",
       "  'unk',\n",
       "  'from',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'tom',\n",
       "  'and',\n",
       "  'mary',\n",
       "  'would',\n",
       "  'like',\n",
       "  'it',\n",
       "  'if',\n",
       "  'i',\n",
       "  'did',\n",
       "  'that',\n",
       "  'for',\n",
       "  'them?',\n",
       "  '</s>'],\n",
       " ['<s>', 'tom', 'and', 'mary', 'unk', 'it', 'with', 'their', 'unk', '</s>'],\n",
       " ['<s>', 'they', 'unk', 'to', 'the', 'unk', 'of', 'the', 'unk', '</s>'],\n",
       " ['<s>',\n",
       "  'you',\n",
       "  'always',\n",
       "  'do',\n",
       "  'that',\n",
       "  'in',\n",
       "  'the',\n",
       "  'unk',\n",
       "  \"don't\",\n",
       "  'you?',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'best',\n",
       "  'unk',\n",
       "  'to',\n",
       "  'unk',\n",
       "  'that',\n",
       "  'problem.',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'tom',\n",
       "  'knew',\n",
       "  'that',\n",
       "  'mary',\n",
       "  'had',\n",
       "  'told',\n",
       "  'john',\n",
       "  'that',\n",
       "  'she',\n",
       "  'saw',\n",
       "  'unk',\n",
       "  'unk',\n",
       "  'another',\n",
       "  'unk',\n",
       "  '</s>'],\n",
       " ['<s>', 'tom', 'unk', 'three', 'unk', 'unk', 'for', 'the', 'party.', '</s>']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "print(\"load training set\")\n",
    "train_data, vocab = load_data(\"train.txt\")\n",
    "\n",
    "## FILL CODE\n",
    "# Same as bigram.py\n",
    "remove_rare_words(train_data, vocab)\n",
    "\n",
    "print(\"load validation set\")\n",
    "valid_data, _ = load_data(\"valid.txt\")\n",
    "remove_rare_words(valid_data, vocab)\n",
    "## FILL CODE\n",
    "# Same as bigram.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram(data, n):\n",
    "    total_number_words = 0\n",
    "    counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "\n",
    "    for sentence in data:\n",
    "        sentence = tuple(sentence)\n",
    "        ## FILL CODE\n",
    "        # dict can be indexed by tuples\n",
    "        # store in the same dict all the ngrams\n",
    "        # by using the context as a key and the word as a value\n",
    "        for i in range(len(sentence)):\n",
    "            temp = sentence[i:n+i]\n",
    "            for j in range(len(temp)):\n",
    "                counts[tuple(temp[:j])][temp[j]] += 1\n",
    "\n",
    "    prob  = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "    ## FILL CODE\n",
    "    # Build the probabilities from the counts\n",
    "    # Be careful with how you normalize!\n",
    "    for p in counts:\n",
    "        s = sum(counts[p].values())\n",
    "        for w in counts[p]:\n",
    "            prob[p][w] = 1.0 * counts[p][w] / s\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build ngram model with n =  4\n"
     ]
    }
   ],
   "source": [
    "# RUN TO BUILD NGRAM MODEL\n",
    "\n",
    "n = 4\n",
    "print(\"build ngram model with n = \", n)\n",
    "model = build_ngram(train_data, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(model, context, w):\n",
    "    ## FILL CODE\n",
    "    # code a recursive function over \n",
    "    # smaller and smaller context\n",
    "    # to compute the backoff model\n",
    "    # Bonus: You can also code an interpolation model this way\n",
    "    #print(tuple(context), w)\n",
    "    if model[tuple(context)][w] != 0:\n",
    "        return model[tuple(context)][w]\n",
    "    else:\n",
    "        return 0.4 * get_prob(model, context[1:], w)\n",
    "\n",
    "def perplexity(model, data, n):\n",
    "    ## FILL CODE\n",
    "    # Same as bigram.py\n",
    "    T = 0\n",
    "    log_sum = 0\n",
    "    \n",
    "    for sentence in data:\n",
    "        prev_word = sentence[:n-1]\n",
    "        for word in sentence[n-1:]:\n",
    "            log_sum += np.log(get_prob(model, prev_word, word))\n",
    "            if prev_word:\n",
    "                prev_word.pop(0)\n",
    "                prev_word.append(word)\n",
    "        T+= len(sentence)\n",
    "    perp = -(log_sum/T)\n",
    "    return perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perplexity is 2.6808364483296296\n"
     ]
    }
   ],
   "source": [
    "# COMPUTE PERPLEXITY ON VALIDATION SET\n",
    "\n",
    "print(\"The perplexity is\", perplexity(model, valid_data, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba_distrib(model, context):\n",
    "    ## FILL CODE\n",
    "    # code a recursive function over context\n",
    "    # to find the longest available ngram  \n",
    "    if sum(model[tuple(context)].values()) > 0:\n",
    "        return  model[tuple(context)]\n",
    "    else:\n",
    "        return get_proba_distrib(model, context[1:])  \n",
    "\n",
    "def generate(model):\n",
    "    ## FILL CODE\n",
    "    # generate a sentence. A sentence starts with a <s> and ends with a </s>\n",
    "    # Possiblly a use function is:\n",
    "    #   np.random.choice(x, 1, p = y)\n",
    "    # where x is a list of things to sample from\n",
    "    # and y is a list of probability (of the same length as x)\n",
    "    sentence = [\"<s>\"]\n",
    "    while True :\n",
    "        world_dict = get_proba_distrib(model, sentence)\n",
    "        p = np.random.choice(list(world_dict.keys()), 1, p = list(world_dict.values()))[0]\n",
    "        sentence.append(p)\n",
    "        if p == \"</s>\": break \n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentence:  ['<s>', 'it', 'looks', 'well', 'unk', 'but', 'you', 'did', 'and', 'now', 'the', 'unk', 'have', 'you', 'unk', 'unk', 'another', 'ten', 'unk', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# GENERATE A SENTENCE FROM THE MODEL\n",
    "\n",
    "print(\"Generated sentence: \",generate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
